{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "897c6366",
   "metadata": {},
   "source": [
    "# Identifier les textes évoquant le concept de république"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a946c393",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(215127, 58)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import csv\n",
    "\n",
    "df = pd.read_csv(\n",
    "    \"../data/interim/data_cleaning.csv\", low_memory=False, dtype={\"ID_orateur\": str}\n",
    ")\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "736da8ed",
   "metadata": {},
   "source": [
    "## INTRODUIRE PRÉ-TRAITEMENT TEXTE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b30ebc5",
   "metadata": {},
   "source": [
    "Pour simplifier la vie et faciliter aussi possibles perf d'un futur modèle, virer les parenthèses et balises ici pour s'économiser pas mal de choses du côté des noms de groupes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c7d67f24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# nettoyage moche du texte\n",
    "\n",
    "\n",
    "def nettoyer_texte(texte):\n",
    "    if not isinstance(texte, str):\n",
    "        return texte\n",
    "    # Supprimer les balises HTML/XML\n",
    "    texte = re.sub(r\"<[^>]+>\", \"\", texte)\n",
    "    # Supprimer contenu entre parenthèses ou crochets\n",
    "    texte = re.sub(r\"\\([^)]*\\)\", \"\", texte)\n",
    "    # # TODO: aviser si enlève crochets, ou juste […] [...], surtout des troncatures citations\n",
    "    # texte = re.sub(r\"\\[[^\\]]*\\]\", \"\", texte)\n",
    "    # Supprimer les espaces multiples\n",
    "    texte = re.sub(r\"\\s+\", \" \", texte).strip()\n",
    "    return texte\n",
    "\n",
    "\n",
    "df[\"Texte_clean\"] = df[\"Texte\"].apply(nettoyer_texte)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53484c90",
   "metadata": {},
   "source": [
    "## Regex"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e39d9cdb",
   "metadata": {},
   "source": [
    "Logique de la tentative :\n",
    "- regex\n",
    "- mais exclure certains termes\n",
    "- mais comme les termes exclus peuvent apparaitre aussi avec les termes voulu, éviter de chainer et finir par virer des trucs qu'on aurait voulu (les idées républicaines sont menacées par Les Républicains)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8d4868f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# préparer les pays à exclure\n",
    "with open(\"../data/interim/liste_pays_republique.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    liste_pays = [line.strip() for line in f]\n",
    "\n",
    "# créer un pattern regex pour les pays\n",
    "# ici pas besoin d'avoir un groupe de capture pas pays mais juste global ok\n",
    "pattern_pays = r\"(\\b(?:\" + r\"|\".join(re.escape(p) for p in liste_pays) + r\")\\b)\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d46a4cf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regex du champ lexical République (simplifié ici)\n",
    "\n",
    "pattern_lexical = re.compile(\n",
    "    r\"républi\", # même au milieu des mots\n",
    "    re.I,\n",
    ")\n",
    "\n",
    "# Regex des expressions à exclure\n",
    "\n",
    "# Expressions à exclure - casse exacte\n",
    "pattern_excl_case_sensitive = re.compile(r\"\\b[LlDd]es Républicains\\b\") # voir pour élu Républicain ? doute\n",
    "\n",
    "# Expressions à exclure - ignorer la casse\n",
    "pattern_excl_case_insensitive = re.compile(\n",
    "    r\"|(\\bprésident[s]? de la République\\b)\"\n",
    "    r\"|(\\bprésidence[s]? de la République\\b)\"\n",
    "    r\"|(\\bgauche démocrate et républicaine)\"\n",
    "    r\"|(\\brépublique en marche\\b)\"\n",
    "    r\"|(\\bprocureur[s]? de la République\\b)\"\n",
    "    r\"|(\\bcour[s]? de justice de la République\\b)\"\n",
    "    r\"|(\\badministration générale de la République\\b)\"\n",
    "    r\"|(\" + pattern_pays + \")\",  # ajout des exclusions de pays si existe\n",
    "    re.I,\n",
    ")\n",
    "\n",
    "def contains_lexical_outside_excl(text):\n",
    "    # Trouver les positions des expressions exclues\n",
    "    excl_positions = []\n",
    "\n",
    "    # Ajouter les exclusions sensibles à la casse\n",
    "    excl_positions.extend(\n",
    "        [m.span() for m in pattern_excl_case_sensitive.finditer(text)]\n",
    "    )\n",
    "\n",
    "    # Ajouter les exclusions insensibles à la casse\n",
    "    excl_positions.extend(\n",
    "        [m.span() for m in pattern_excl_case_insensitive.finditer(text)]\n",
    "    )\n",
    "\n",
    "    # Fonction pour vérifier si une position est dans une zone exclue\n",
    "    def in_excl(pos):\n",
    "        for start, end in excl_positions:\n",
    "            if start <= pos < end:\n",
    "                return True\n",
    "        return False\n",
    "\n",
    "    # Chercher toutes les occurences du champ lexical\n",
    "    for match in pattern_lexical.finditer(text):\n",
    "        start_pos = match.start()\n",
    "        if not in_excl(start_pos):\n",
    "            return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "89420e78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # bloc d'essai\n",
    "# mon_texte = \"La république démocratique du congo et instituteurs de la République.\"\n",
    "# contains_lexical_outside_excl(mon_texte)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b83da332",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Appliquer sur la colonne\n",
    "df[\"repu_match_valide\"] = df[\"Texte_clean\"].apply(contains_lexical_outside_excl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "013aa286",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3668, 60)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_match = df[df[\"repu_match_valide\"]]\n",
    "df_match.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "36e521a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_match.to_csv(\n",
    "    \"../data/interim/df_repu.csv\",\n",
    "    index=False,\n",
    "    quoting=csv.QUOTE_ALL,  # a permis de résoudre le soucis d'écart. Checker\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "177fc0bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3668, 60)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# vérif écriture/lecture ok\n",
    "df_test = pd.read_csv(\"../data/interim/df_repu.csv\")\n",
    "df_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4f1b275",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv_clone",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
