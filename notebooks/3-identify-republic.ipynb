{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "897c6366",
   "metadata": {},
   "source": [
    "# Identifier les textes évoquant le concept de république"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d48cd88",
   "metadata": {},
   "source": [
    "TODO:\n",
    "Premier pb ici : vérifier d'ou vient mais\n",
    "- changement taille fichier entrée (check)\n",
    "- ex avant de changer cleaning ave le join : 129769 / puis\n",
    "- VÉRIF ÉCRITURE DU CSV QUI DOIT MERDER ????\n",
    "- -> C'est le join avant qui visiblement introduit une merde\n",
    "- mais ne change pas la structure du df avant l'export/reimport\n",
    "- résolu en forçant le quote à l'export du csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a946c393",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\n",
    "    \"../data/interim/data_cleaning.csv\", low_memory=False, dtype={\"ID_orateur\": str}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a48f20eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(129769, 59)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ICI ÇA MERDAIT ENTRE LA SORTIE JUSTE AVANT ET LA LECTURE ET IMPORT DU DF\n",
    "# Resolu avec quotes\n",
    "# Voir pourquoi et ou est le pb quand même dans les cols du join > certains noms de sites et réseaux sociaux apparement\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e39d9cdb",
   "metadata": {},
   "source": [
    "Logique de la tentative :\n",
    "- regex\n",
    "- mais exclure certains termes\n",
    "- mais comme les termes exclus peuvent apparaitre aussi avec les termes voulu, éviter de chainer et finir par virer des trucs qu'on aurait voulu (les idées républicaines sont menacées par Les Républicains)\n",
    "- Mais comme je suis pas bien sur de moin tentative GPT à vérifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "736da8ed",
   "metadata": {},
   "source": [
    "## INTRODUIRE PRÉ-TRAITEMENT TEXTE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b30ebc5",
   "metadata": {},
   "source": [
    "Pour simplifier la vie et faciliter aussi possibles perf d'un futur modèle, virer les parenthèses et balises ici pour s'économiser pas mal de choses du côté des noms de groupes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "c7d67f24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# nettoyage moche du texte\n",
    "# sinon à gérer avant !\n",
    "\n",
    "import re\n",
    "\n",
    "\n",
    "def nettoyer_texte(texte):\n",
    "    if not isinstance(texte, str):\n",
    "        return texte\n",
    "    # Supprimer les balises HTML/XML\n",
    "    texte = re.sub(r\"<[^>]+>\", \"\", texte)\n",
    "    # Supprimer contenu entre parenthèses ou crochets\n",
    "    texte = re.sub(r\"\\([^)]*\\)\", \"\", texte)  # (...)\n",
    "    # texte = re.sub(r\"\\[[^\\]]*\\]\", \"\", texte)     # [...] # TODO: vérif avant\n",
    "    # Supprimer les espaces multiples\n",
    "    texte = re.sub(r\"\\s+\", \" \", texte).strip()\n",
    "    return texte\n",
    "\n",
    "\n",
    "df[\"Texte_clean\"] = df[\"Texte\"].apply(nettoyer_texte)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45f266d2",
   "metadata": {},
   "source": [
    "appliquer le traitement avant fait passer de à 4592 à 4408 (avec la version basique de la regex. Sans doute le groupe socialiste gauche républicaine entre parenthèses, etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "a91d03df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO : affiner et notamment les exclusions :\n",
    "# procureur de la république, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5692c9e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "# Regex du champ lexical République (simplifié ici)\n",
    "\n",
    "# sinon :\n",
    "\n",
    "pattern_lexical = re.compile(\n",
    "    # r\"(?<!\\w)(anti-?|pré-?|post-?|pro?)?(république(s)?|républicain(e)?s?|républicanisme|républicanis(er|ation))\\b\",\n",
    "    r\"républi\",\n",
    "    re.I,\n",
    "#######################\n",
    "# Ancienne version : mais en fait aller au plus simple\n",
    "#######################\n",
    "\n",
    "# pattern_lexical = re.compile(\n",
    "#     # r\"(?<!\\w)(anti-?|pré-?|post-?|pro?)?(république(s)?|républicain(e)?s?|républicanisme|républicanis(er|ation))\\b\",\n",
    "#     r\"(république(s)?|républicain(e)?s?|républicanisme(s)?|républicanis(er|ation))\",\n",
    "#     re.I,\n",
    "# )\n",
    "# au pire virer le (?<!\\w)(anti-?|pré-?|post-?|pro?)?\n",
    "# genre on raterait irrépublicain\n",
    "# aussi viré finalement la fin de mot (ce qui permettrait de matcher les s etc. sans se casser les pieds)\n",
    "\n",
    "########################\n",
    "\n",
    "# Regex des expressions à exclure\n",
    "pattern_excl = re.compile(\n",
    "    r\"\\b(L|l)es Républicains\\b|(P|p)résident de la République\"\n",
    ")  # ici garder la casse\n",
    "\n",
    "\n",
    "def contains_lexical_outside_excl(text):\n",
    "    # Trouve toutes les positions des expressions exclues\n",
    "    excl_positions = [m.span() for m in pattern_excl.finditer(text)]\n",
    "\n",
    "    # Fonction pour vérifier si une position est dans une zone exclue\n",
    "    def in_excl(pos):\n",
    "        for start, end in excl_positions:\n",
    "            if start <= pos < end:\n",
    "                return True\n",
    "        return False\n",
    "\n",
    "    # Chercher toutes les occurences du champ lexical\n",
    "    for match in pattern_lexical.finditer(text):\n",
    "        start_pos = match.start()\n",
    "        if not in_excl(start_pos):\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "\n",
    "# Appliquer sur la colonne\n",
    "df[\"repu_match_valide\"] = df[\"Texte_clean\"].apply(contains_lexical_outside_excl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "6020dccf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4409, 61)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df[\"repu_match_valide\"]].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "44d53fee",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/rq/xsj46x_s2rg87wdksm1_jl3c0000gn/T/ipykernel_4241/1776404343.py:3: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  lexical_mask = df[\"Texte_clean\"].str.contains(pattern_lexical)\n",
      "/var/folders/rq/xsj46x_s2rg87wdksm1_jl3c0000gn/T/ipykernel_4241/1776404343.py:6: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  excl_mask = df[\"Texte_clean\"].str.contains(pattern_excl)\n"
     ]
    }
   ],
   "source": [
    "# Version bourrin\n",
    "# Champ lexical : True si le texte contient un terme du champ lexical\n",
    "lexical_mask = df[\"Texte_clean\"].str.contains(pattern_lexical)\n",
    "\n",
    "# Exclusion : True si le texte contient une expression à exclure\n",
    "excl_mask = df[\"Texte_clean\"].str.contains(pattern_excl)\n",
    "\n",
    "# On garde ceux qui matchent lexicalement mais ne contiennent pas d'exclusion\n",
    "df[\"repu_match_simple\"] = lexical_mask & ~excl_mask\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "52a59730",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3926, 62)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df[\"repu_match_simple\"]].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "36e521a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "df_match = df[df[\"repu_match_valide\"]]\n",
    "df_match.to_csv(\n",
    "    \"../data/interim/df_repu.csv\",\n",
    "    index=False,\n",
    "    quoting=csv.QUOTE_ALL,  # a permis de résoudre le soucis d'écart. Checker\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "94cc259a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4409, 62)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_match.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "177fc0bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_csv(\"../data/interim/df_repu.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "2b5528dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4409, 62)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv_clone",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
