{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "15f284a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# bug incompatibilité dans myenv_clone, ok dans nlp_env\n",
    "# faire du nettoyage dans les envs un jour …\n",
    "import os\n",
    "from ollama import Client\n",
    "\n",
    "OLLAMA_HOST = os.environ.get(\"OLLAMA_HOST\")\n",
    "client = Client(host=OLLAMA_HOST)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5bf4d1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\n",
    "    \"../data/interim/annotations_republique-annotation_previous_annotation_test.csv\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "347c5745",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>previous_annotation</th>\n",
       "      <th>user</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>comment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3088159</td>\n",
       "      <td>Les Jeux olympiques et paralympiques sont une ...</td>\n",
       "      <td>Republique</td>\n",
       "      <td>levallet</td>\n",
       "      <td>2025-07-02 09:43:06.346438+00:00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2930452</td>\n",
       "      <td>C’est pourquoi notre texte demande l’exclusion...</td>\n",
       "      <td>Autre</td>\n",
       "      <td>levallet</td>\n",
       "      <td>2025-07-02 09:43:25.957983+00:00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>3325331</td>\n",
       "      <td>Peut-être, mais quoi qu’il en soit, le préside...</td>\n",
       "      <td>Republique</td>\n",
       "      <td>levallet</td>\n",
       "      <td>2025-07-02 09:44:00.172319+00:00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3488029</td>\n",
       "      <td>Ainsi que nous l’avons déjà exprimé en commiss...</td>\n",
       "      <td>Republique</td>\n",
       "      <td>levallet</td>\n",
       "      <td>2025-07-02 09:44:47.237938+00:00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>3487031</td>\n",
       "      <td>La sécurité sociale « est la garantie donnée à...</td>\n",
       "      <td>Republique</td>\n",
       "      <td>levallet</td>\n",
       "      <td>2025-07-02 09:45:14.901417+00:00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0       id                                               text  \\\n",
       "0           0  3088159  Les Jeux olympiques et paralympiques sont une ...   \n",
       "1           1  2930452  C’est pourquoi notre texte demande l’exclusion...   \n",
       "2           2  3325331  Peut-être, mais quoi qu’il en soit, le préside...   \n",
       "3           3  3488029  Ainsi que nous l’avons déjà exprimé en commiss...   \n",
       "4           4  3487031  La sécurité sociale « est la garantie donnée à...   \n",
       "\n",
       "  previous_annotation      user                         timestamp  comment  \n",
       "0          Republique  levallet  2025-07-02 09:43:06.346438+00:00      NaN  \n",
       "1               Autre  levallet  2025-07-02 09:43:25.957983+00:00      NaN  \n",
       "2          Republique  levallet  2025-07-02 09:44:00.172319+00:00      NaN  \n",
       "3          Republique  levallet  2025-07-02 09:44:47.237938+00:00      NaN  \n",
       "4          Republique  levallet  2025-07-02 09:45:14.901417+00:00      NaN  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "336d62a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "previous_annotation\n",
       "Republique    92\n",
       "Autre          8\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"previous_annotation\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1ed61b36",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "def do_predictions(prompt_generator, texts, model):\n",
    "    \"\"\"\n",
    "    Prediction avec Ollama : prompt_generator, liste de textes, modèle.\n",
    "    Affiche la progression (tqdm).\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    total = len(texts)\n",
    "\n",
    "    with tqdm(\n",
    "        total=total,\n",
    "        desc=\"Progress\",\n",
    "        unit=\"item\",\n",
    "        bar_format=\"{l_bar}{bar} | {n_fmt}/{total_fmt} [{percentage:3.0f}%]\",\n",
    "    ) as pbar:\n",
    "        for i, text in texts.items():\n",
    "            try:\n",
    "                messages = prompt_generator(text)\n",
    "                response = client.chat(model=model, messages=messages)\n",
    "                content = response.get(\"message\", {}).get(\"content\", \"\").strip()\n",
    "                results.append(content)\n",
    "            except Exception as e:\n",
    "                print(f\"Erreur ligne {i} : {e}\")\n",
    "                results.append(None)\n",
    "            pbar.update(1)\n",
    "\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e888d025",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: need to check prompt struct to be sure of what is going to ollama\n",
    "def get_prompt_simple(text):\n",
    "    return [\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": (\n",
    "                \"Tu es un expert en sciences politique. \"\n",
    "                \"Classifie chaque intervention comme relevant du thème 'REPUBLIQUE' ou 'AUTRE'\"\n",
    "                \"Réponds uniquement par un de ces deux mots\"\n",
    "            ),\n",
    "        },\n",
    "        {\"role\": \"user\", \"content\": f'Classe cette intervention :\\n\"{text}\"\\nLabel:'},\n",
    "    ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "5243c24e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: need to check prompt struct to be sure of what is going to ollama\n",
    "def get_prompt_exclure_pays(text):\n",
    "    return [\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": (\n",
    "                \"Tu es un expert en sciences politique. \"\n",
    "                \"Tu dois classifier chaque intervention comme relevant bien du thème de la 'REPUBLIQUE' française ou 'AUTRE\"\n",
    "                \"Fais attention à exclure celles qui ne parlent que d'autres pays (=AUTRE)\"\n",
    "                \"Réponds uniquement par un de ces deux mots ('REPUBLIQUE' ou 'AUTRE')\"\n",
    "            ),\n",
    "        },\n",
    "        {\"role\": \"user\", \"content\": f'Classe cette intervention :\\n\"{text}\"\\nLabel:'},\n",
    "    ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "182bd5b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # S'inspirer de ça si besoin ?\n",
    "# # The structure is a bit different\n",
    "# def build_prompt(text):\n",
    "#     system_prompt = (\n",
    "#         \"You are a helpful and accurate news headline classifier. \"\n",
    "#         \"Your job is to classify news headlines as either 'POLITICS' or 'OTHER'. \"\n",
    "#         \"Only respond with exactly one of those two labels.\"\n",
    "#     )\n",
    "#     user_prompt = f\"Classify this headline:\\n\\\"{text}\\\"\\nLabel:\"\n",
    "#     return f\"<<SYS>>\\n{system_prompt}\\n<</SYS>>\\n\\n[INST] {user_prompt} [/INST]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "0a5a949b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress: 100%|██████████ | 100/100 [100%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Temps d'exécution : 64.54 secondes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "# si abesoin ajout pause, un truc du genre ?\n",
    "\n",
    "# # test avec un extrait\n",
    "# texts = df[\"Texte\"][:100]  # ou .iloc[:blabla]\n",
    "\n",
    "start = time.time()\n",
    "# Appel\n",
    "r_ollama = do_predictions(get_prompt_exclure_pays, df[\"text\"], model=\"llama3.1:70b\")\n",
    "end = time.time()\n",
    "print(f\"Temps d'exécution : {end - start:.2f} secondes\")\n",
    "\n",
    "# # Ajout dans le DataFrame\n",
    "# df.loc[texts.index, \"prediction_simple\"] = r_ollama\n",
    "\n",
    "# guess it kinda work ? puisque à tout pris.\n",
    "# Si slice ici aussi renvoyer le slice.index\n",
    "df.loc[df[\"text\"].index, \"prediction_llama_exclure_pays\"] = r_ollama\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "5eb9510a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"../data/interim/df_testset_pred_simple_llama.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1d84899",
   "metadata": {},
   "source": [
    "## longer prompt ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1732cf35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # TODO: need to check prompt struct to be sure of what is going to ollama\n",
    "\n",
    "\n",
    "# def get_prompt_long(text):\n",
    "#     return [\n",
    "#         {\n",
    "#             \"role\": \"system\",\n",
    "#             \"content\": (\n",
    "#                 \"Dans le cadre d’un article académique en science politique, tu dois distinguer les interventions relatives à la 'République' des 'autres' \"\n",
    "#                 \"Il s’agit d’un corpus d’interventions de députés à l’assemblée nationale en France lors de la 16e législature.\"\n",
    "#                 \" La « République » renvoie ici à sa dimension idéelle ou idéologique. Est donc exclut les références à des pays, au nom d’un parti politique, d’un journaliste ou d’une institution, ou à la fonction de président de la République. Est inclut en plus du champ lexical de la « République », à la devise « liberté, égalité, fraternité » et aux principes de « laïcité », « universalisme » et « indivisibilité ». \"\n",
    "#                 \"Classifie chaque intervention comme 'REPUBLIQUE' ou 'AUTRE'\"\n",
    "#                 \"Réponds uniquement par un de ces deux mots.\"\n",
    "#             ),\n",
    "#         },\n",
    "#         {\"role\": \"user\", \"content\": f'Classe cette intervention :\\n\"{text}\"\\nLabel:'},\n",
    "#     ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e8ab6f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress: 100%|██████████ | 100/100 [100%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Temps d'exécution : 78.47 secondes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# import time\n",
    "\n",
    "# # test avec un extrait\n",
    "# texts = df[\"Texte\"][:100]  # ou .iloc[:10]\n",
    "\n",
    "# start = time.time()\n",
    "# # Appel\n",
    "# r_ollama = do_predictions(get_prompt_long, texts, model=\"llama3.1:70b\")\n",
    "# end = time.time()\n",
    "# print(f\"Temps d'exécution : {end - start:.2f} secondes\")\n",
    "\n",
    "# # Ajout dans le DataFrame\n",
    "# df.loc[texts.index, \"prediction_long\"] = r_ollama"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a88af42e",
   "metadata": {},
   "source": [
    "# Experimentation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "108545e0",
   "metadata": {},
   "source": [
    "## Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "7d55c357",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"prediction_llama_simple\"] = df[\"prediction_llama_simple\"].replace(\n",
    "    {\"REPUBLIQUE\": \"Republique\", \"AUTRE\": \"Autre\"}\n",
    ")\n",
    "\n",
    "df[\"prediction_llama_exclure_pays\"] = df[\"prediction_llama_exclure_pays\"].replace(\n",
    "    {\"REPUBLIQUE\": \"Republique\", \"AUTRE\": \"Autre\"}\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "0fdd434e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>previous_annotation</th>\n",
       "      <th>prediction_llama_simple</th>\n",
       "      <th>prediction_llama_exclure_pays</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Republique</td>\n",
       "      <td>Republique</td>\n",
       "      <td>Republique</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Autre</td>\n",
       "      <td>Republique</td>\n",
       "      <td>Autre</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Republique</td>\n",
       "      <td>Autre</td>\n",
       "      <td>Republique</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Republique</td>\n",
       "      <td>Autre</td>\n",
       "      <td>Republique</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Republique</td>\n",
       "      <td>Republique</td>\n",
       "      <td>Republique</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Republique</td>\n",
       "      <td>Republique</td>\n",
       "      <td>Republique</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Republique</td>\n",
       "      <td>Republique</td>\n",
       "      <td>Republique</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Republique</td>\n",
       "      <td>Autre</td>\n",
       "      <td>Republique</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Autre</td>\n",
       "      <td>Autre</td>\n",
       "      <td>Republique</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Republique</td>\n",
       "      <td>Republique</td>\n",
       "      <td>Republique</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   previous_annotation prediction_llama_simple prediction_llama_exclure_pays\n",
       "0           Republique              Republique                    Republique\n",
       "1                Autre              Republique                         Autre\n",
       "2           Republique                   Autre                    Republique\n",
       "3           Republique                   Autre                    Republique\n",
       "4           Republique              Republique                    Republique\n",
       "..                 ...                     ...                           ...\n",
       "95          Republique              Republique                    Republique\n",
       "96          Republique              Republique                    Republique\n",
       "97          Republique                   Autre                    Republique\n",
       "98               Autre                   Autre                    Republique\n",
       "99          Republique              Republique                    Republique\n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[[\"previous_annotation\", \"prediction_llama_simple\", \"prediction_llama_exclure_pays\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "85769158",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>previous_annotation</th>\n",
       "      <th>prediction_llama_simple</th>\n",
       "      <th>prediction_llama_exclure_pays</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3088159</td>\n",
       "      <td>Les Jeux olympiques et paralympiques sont une ...</td>\n",
       "      <td>Republique</td>\n",
       "      <td>Republique</td>\n",
       "      <td>Republique</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2930452</td>\n",
       "      <td>C’est pourquoi notre texte demande l’exclusion...</td>\n",
       "      <td>Autre</td>\n",
       "      <td>Republique</td>\n",
       "      <td>Autre</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3325331</td>\n",
       "      <td>Peut-être, mais quoi qu’il en soit, le préside...</td>\n",
       "      <td>Republique</td>\n",
       "      <td>Autre</td>\n",
       "      <td>Republique</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3488029</td>\n",
       "      <td>Ainsi que nous l’avons déjà exprimé en commiss...</td>\n",
       "      <td>Republique</td>\n",
       "      <td>Autre</td>\n",
       "      <td>Republique</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3487031</td>\n",
       "      <td>La sécurité sociale « est la garantie donnée à...</td>\n",
       "      <td>Republique</td>\n",
       "      <td>Republique</td>\n",
       "      <td>Republique</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id                                               text  \\\n",
       "0  3088159  Les Jeux olympiques et paralympiques sont une ...   \n",
       "1  2930452  C’est pourquoi notre texte demande l’exclusion...   \n",
       "2  3325331  Peut-être, mais quoi qu’il en soit, le préside...   \n",
       "3  3488029  Ainsi que nous l’avons déjà exprimé en commiss...   \n",
       "4  3487031  La sécurité sociale « est la garantie donnée à...   \n",
       "\n",
       "  previous_annotation prediction_llama_simple prediction_llama_exclure_pays  \n",
       "0          Republique              Republique                    Republique  \n",
       "1               Autre              Republique                         Autre  \n",
       "2          Republique                   Autre                    Republique  \n",
       "3          Republique                   Autre                    Republique  \n",
       "4          Republique              Republique                    Republique  "
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import classification_report, f1_score\n",
    "\n",
    "# df_score = pd.read_csv(\"../data/interim/df_merged_pred.csv\")\n",
    "df_score = df[[\"id\", \"text\", \"previous_annotation\", \"prediction_llama_simple\", \"prediction_llama_exclure_pays\"]]\n",
    "df_score.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "a8339845",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Autre      0.667     0.250     0.364         8\n",
      "  Republique      0.938     0.989     0.963        92\n",
      "\n",
      "    accuracy                          0.930       100\n",
      "   macro avg      0.802     0.620     0.663       100\n",
      "weighted avg      0.916     0.930     0.915       100\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# pour le principe, puisque ici pas de gold standard, juste les modèles entre eux\n",
    "print(\n",
    "    classification_report(\n",
    "        df_score[\"previous_annotation\"], df_score[\"prediction_llama_exclure_pays\"], digits=3\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "cacea899",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6632996632996633"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(\n",
    "    df_score[\"previous_annotation\"],\n",
    "    df_score[\"prediction_llama_exclure_pays\"],\n",
    "    average=\"macro\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "7e555ff8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>prediction_llama_exclure_pays</th>\n",
       "      <th>Autre</th>\n",
       "      <th>Republique</th>\n",
       "      <th>Total</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>previous_annotation</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Autre</th>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Republique</th>\n",
       "      <td>1</td>\n",
       "      <td>91</td>\n",
       "      <td>92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Total</th>\n",
       "      <td>3</td>\n",
       "      <td>97</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "prediction_llama_exclure_pays  Autre  Republique  Total\n",
       "previous_annotation                                    \n",
       "Autre                              2           6      8\n",
       "Republique                         1          91     92\n",
       "Total                              3          97    100"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# comparer les modèles\n",
    "pd.crosstab(\n",
    "    df_score[\"previous_annotation\"],\n",
    "    df_score[\"prediction_llama_exclure_pays\"],\n",
    "    margins=True,\n",
    "    margins_name=\"Total\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67121355",
   "metadata": {},
   "source": [
    "## Few-shot ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54426f76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Let's build the prompt, with some examples\n",
    "# few_shot_examples = [\n",
    "#         (\"Biden signs executive order on student debt relief\", \"POLITICS\"),\n",
    "#         (\"Amazon launches new AI-powered Alexa features\", \"OTHER\"),\n",
    "#         (\"Congress debates military spending bill\", \"POLITICS\"),\n",
    "#         (\"PSG wins much-anticipated Champions League\", \"OTHER\")\n",
    "#         ]\n",
    "\n",
    "# def get_prompt_few_shots(text: str, examples: list[tuple] = few_shot_examples):\n",
    "#   examples = \"\\n\".join([f\"Classify this headline:\\n{headline}\\nLabel: {label}\\n\\n\" for headline, label in examples])\n",
    "#   return [{\"role\":\"system\",\n",
    "#            \"content\":\"You are a strict news classifier. You must respond with one word only — either 'POLITICS' or 'OTHER'.\" +\n",
    "#            \"\\n Do not explain. Do not output anything else.\"\n",
    "\n",
    "#            },\n",
    "#            {\"role\":\"user\",\"content\": f\"{examples}\\nClassify this headline:\\n\\\"{text}\\\"\\nLabel:\"}\n",
    "#   ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d771928",
   "metadata": {},
   "source": [
    "## Refacto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b0b9332",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Inspiration GPT pour avoir des checkpoints :\n",
    "# results = []\n",
    "# indexes = []\n",
    "# batch_size = 20\n",
    "\n",
    "# for i in range(0, len(df), batch_size):\n",
    "#     batch = df[\"Texte\"].iloc[i:i+batch_size]\n",
    "#     try:\n",
    "#         r_batch, _ = do_predictions(get_prompt, batch, model=\"llama3.1:70b\")\n",
    "#         results.extend(r_batch)\n",
    "#         indexes.extend(batch.index)\n",
    "\n",
    "#         # Checkpoint every 100 samples\n",
    "#         if i % 100 == 0:\n",
    "#             df.loc[indexes, \"prediction_simple\"] = results\n",
    "#             df.to_csv(\"checkpoint_predictions.csv\", index=False)\n",
    "#             print(f\"Checkpoint sauvegardé à {i}.\")\n",
    "\n",
    "#         time.sleep(1)  # optional pause\n",
    "\n",
    "#     except Exception as e:\n",
    "#         print(f\"Erreur au batch {i}: {e}\")\n",
    "#         continue\n",
    "\n",
    "# df.loc[indexes, \"prediction_simple\"] = results\n",
    "# df.to_csv(\"final_predictions.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdf68914",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Et même inspiration pour un truc encore plus complet, mais overkill pour l'instant\n",
    "\n",
    "# import os\n",
    "# import time\n",
    "# import pandas as pd\n",
    "# from datetime import datetime\n",
    "\n",
    "\n",
    "# def ensure_dir(path):\n",
    "#     if not os.path.exists(path):\n",
    "#         os.makedirs(path)\n",
    "\n",
    "\n",
    "# def timestamp():\n",
    "#     return datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "\n",
    "\n",
    "# def do_predictions(prompt_func, texts, model):\n",
    "#     prompt_name = prompt_func.__name__\n",
    "#     results = [prompt_func(text) for text in texts]\n",
    "#     return results, prompt_name\n",
    "\n",
    "\n",
    "# def run_llm_batches(df, text_column, prompt_func, model,\n",
    "#                     column_name=None, batch_size=20, sleep_time=1,\n",
    "#                     checkpoint_every=100, output_dir=\"outputs\"):\n",
    "\n",
    "#     # Setup\n",
    "#     start = time.time()\n",
    "#     all_results = []\n",
    "#     all_indexes = []\n",
    "#     name = prompt_func.__name__ if column_name is None else column_name\n",
    "\n",
    "#     ensure_dir(output_dir)\n",
    "\n",
    "#     print(f\"🚀 Début du traitement avec le prompt '{name}' et le modèle '{model}'\")\n",
    "\n",
    "#     # Boucle par batch\n",
    "#     for i in range(0, len(df), batch_size):\n",
    "#         batch = df[text_column].iloc[i:i + batch_size]\n",
    "#         idx = batch.index\n",
    "\n",
    "#         try:\n",
    "#             batch_start = time.time()\n",
    "#             r_batch, _ = do_predictions(prompt_func, batch, model=model)\n",
    "#             all_results.extend(r_batch)\n",
    "#             all_indexes.extend(idx)\n",
    "#             print(f\"✅ Batch {i}-{i + batch_size} traité en {time.time() - batch_start:.2f}s\")\n",
    "\n",
    "#             # Sauvegarde périodique\n",
    "#             if (i // batch_size) % (checkpoint_every // batch_size) == 0:\n",
    "#                 df.loc[all_indexes, name] = all_results\n",
    "#                 ckpt_file = os.path.join(output_dir, f\"checkpoint_{name}_{timestamp()}.csv\")\n",
    "#                 df.to_csv(ckpt_file, index=False)\n",
    "#                 print(f\"💾 Checkpoint enregistré : {ckpt_file}\")\n",
    "\n",
    "#             time.sleep(sleep_time)\n",
    "\n",
    "#         except Exception as e:\n",
    "#             print(f\"⚠️ Erreur au batch {i}-{i + batch_size}: {e}\")\n",
    "#             continue\n",
    "\n",
    "#     # Résultat final\n",
    "#     df.loc[all_indexes, name] = all_results\n",
    "#     final_file = os.path.join(output_dir, f\"final_{name}_{timestamp()}.csv\")\n",
    "#     df.to_csv(final_file, index=False)\n",
    "\n",
    "#     print(f\"🏁 Traitement terminé en {time.time() - start:.2f}s\")\n",
    "#     print(f\"📝 Résultat final enregistré : {final_file}\")\n",
    "#     return df\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
