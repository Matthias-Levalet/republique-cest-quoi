{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "15f284a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# bug incompatibilit√© dans myenv_clone, ok dans nlp_env\n",
    "# faire du nettoyage dans les envs un jour ‚Ä¶\n",
    "import os\n",
    "from ollama import Client\n",
    "\n",
    "OLLAMA_HOST = os.environ.get(\"OLLAMA_HOST\")\n",
    "client = Client(host=OLLAMA_HOST)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5bf4d1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\n",
    "    \"../data/interim/annotations_republique-annotation_previous_annotation_test.csv\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "347c5745",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>previous_annotation</th>\n",
       "      <th>user</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>comment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3088159</td>\n",
       "      <td>Les Jeux olympiques et paralympiques sont une ...</td>\n",
       "      <td>Republique</td>\n",
       "      <td>levallet</td>\n",
       "      <td>2025-07-02 09:43:06.346438+00:00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2930452</td>\n",
       "      <td>C‚Äôest pourquoi notre texte demande l‚Äôexclusion...</td>\n",
       "      <td>Autre</td>\n",
       "      <td>levallet</td>\n",
       "      <td>2025-07-02 09:43:25.957983+00:00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>3325331</td>\n",
       "      <td>Peut-√™tre, mais quoi qu‚Äôil en soit, le pr√©side...</td>\n",
       "      <td>Republique</td>\n",
       "      <td>levallet</td>\n",
       "      <td>2025-07-02 09:44:00.172319+00:00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3488029</td>\n",
       "      <td>Ainsi que nous l‚Äôavons d√©j√† exprim√© en commiss...</td>\n",
       "      <td>Republique</td>\n",
       "      <td>levallet</td>\n",
       "      <td>2025-07-02 09:44:47.237938+00:00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>3487031</td>\n",
       "      <td>La s√©curit√© sociale ¬´ est la garantie donn√©e √†...</td>\n",
       "      <td>Republique</td>\n",
       "      <td>levallet</td>\n",
       "      <td>2025-07-02 09:45:14.901417+00:00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0       id                                               text  \\\n",
       "0           0  3088159  Les Jeux olympiques et paralympiques sont une ...   \n",
       "1           1  2930452  C‚Äôest pourquoi notre texte demande l‚Äôexclusion...   \n",
       "2           2  3325331  Peut-√™tre, mais quoi qu‚Äôil en soit, le pr√©side...   \n",
       "3           3  3488029  Ainsi que nous l‚Äôavons d√©j√† exprim√© en commiss...   \n",
       "4           4  3487031  La s√©curit√© sociale ¬´ est la garantie donn√©e √†...   \n",
       "\n",
       "  previous_annotation      user                         timestamp  comment  \n",
       "0          Republique  levallet  2025-07-02 09:43:06.346438+00:00      NaN  \n",
       "1               Autre  levallet  2025-07-02 09:43:25.957983+00:00      NaN  \n",
       "2          Republique  levallet  2025-07-02 09:44:00.172319+00:00      NaN  \n",
       "3          Republique  levallet  2025-07-02 09:44:47.237938+00:00      NaN  \n",
       "4          Republique  levallet  2025-07-02 09:45:14.901417+00:00      NaN  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "336d62a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "previous_annotation\n",
       "Republique    92\n",
       "Autre          8\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"previous_annotation\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1ed61b36",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "def do_predictions(prompt_generator, texts, model):\n",
    "    \"\"\"\n",
    "    Prediction avec Ollama : prompt_generator, liste de textes, mod√®le.\n",
    "    Affiche la progression (tqdm).\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    total = len(texts)\n",
    "\n",
    "    with tqdm(\n",
    "        total=total,\n",
    "        desc=\"Progress\",\n",
    "        unit=\"item\",\n",
    "        bar_format=\"{l_bar}{bar} | {n_fmt}/{total_fmt} [{percentage:3.0f}%]\",\n",
    "    ) as pbar:\n",
    "        for i, text in texts.items():\n",
    "            try:\n",
    "                messages = prompt_generator(text)\n",
    "                response = client.chat(model=model, messages=messages)\n",
    "                content = response.get(\"message\", {}).get(\"content\", \"\").strip()\n",
    "                results.append(content)\n",
    "            except Exception as e:\n",
    "                print(f\"Erreur ligne {i} : {e}\")\n",
    "                results.append(None)\n",
    "            pbar.update(1)\n",
    "\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e888d025",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: need to check prompt struct to be sure of what is going to ollama\n",
    "def get_prompt_simple(text):\n",
    "    return [\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": (\n",
    "                \"Tu es un expert en sciences politique. \"\n",
    "                \"Classifie chaque intervention comme relevant du th√®me 'REPUBLIQUE' ou 'AUTRE'\"\n",
    "                \"R√©ponds uniquement par un de ces deux mots\"\n",
    "            ),\n",
    "        },\n",
    "        {\"role\": \"user\", \"content\": f'Classe cette intervention :\\n\"{text}\"\\nLabel:'},\n",
    "    ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "5243c24e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: need to check prompt struct to be sure of what is going to ollama\n",
    "def get_prompt_exclure_pays(text):\n",
    "    return [\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": (\n",
    "                \"Tu es un expert en sciences politique. \"\n",
    "                \"Tu dois classifier chaque intervention comme relevant bien du th√®me de la 'REPUBLIQUE' fran√ßaise ou 'AUTRE\"\n",
    "                \"Fais attention √† exclure celles qui ne parlent que d'autres pays (=AUTRE)\"\n",
    "                \"R√©ponds uniquement par un de ces deux mots ('REPUBLIQUE' ou 'AUTRE')\"\n",
    "            ),\n",
    "        },\n",
    "        {\"role\": \"user\", \"content\": f'Classe cette intervention :\\n\"{text}\"\\nLabel:'},\n",
    "    ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "182bd5b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # S'inspirer de √ßa si besoin ?\n",
    "# # The structure is a bit different\n",
    "# def build_prompt(text):\n",
    "#     system_prompt = (\n",
    "#         \"You are a helpful and accurate news headline classifier. \"\n",
    "#         \"Your job is to classify news headlines as either 'POLITICS' or 'OTHER'. \"\n",
    "#         \"Only respond with exactly one of those two labels.\"\n",
    "#     )\n",
    "#     user_prompt = f\"Classify this headline:\\n\\\"{text}\\\"\\nLabel:\"\n",
    "#     return f\"<<SYS>>\\n{system_prompt}\\n<</SYS>>\\n\\n[INST] {user_prompt} [/INST]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "0a5a949b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 100/100 [100%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Temps d'ex√©cution : 64.54 secondes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "# si abesoin ajout pause, un truc du genre ?\n",
    "\n",
    "# # test avec un extrait\n",
    "# texts = df[\"Texte\"][:100]  # ou .iloc[:blabla]\n",
    "\n",
    "start = time.time()\n",
    "# Appel\n",
    "r_ollama = do_predictions(get_prompt_exclure_pays, df[\"text\"], model=\"llama3.1:70b\")\n",
    "end = time.time()\n",
    "print(f\"Temps d'ex√©cution : {end - start:.2f} secondes\")\n",
    "\n",
    "# # Ajout dans le DataFrame\n",
    "# df.loc[texts.index, \"prediction_simple\"] = r_ollama\n",
    "\n",
    "# guess it kinda work ? puisque √† tout pris.\n",
    "# Si slice ici aussi renvoyer le slice.index\n",
    "df.loc[df[\"text\"].index, \"prediction_llama_exclure_pays\"] = r_ollama\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "5eb9510a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"../data/interim/df_testset_pred_simple_llama.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1d84899",
   "metadata": {},
   "source": [
    "## longer prompt ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1732cf35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # TODO: need to check prompt struct to be sure of what is going to ollama\n",
    "\n",
    "\n",
    "# def get_prompt_long(text):\n",
    "#     return [\n",
    "#         {\n",
    "#             \"role\": \"system\",\n",
    "#             \"content\": (\n",
    "#                 \"Dans le cadre d‚Äôun article acad√©mique en science politique, tu dois distinguer les interventions relatives √† la 'R√©publique' des 'autres' \"\n",
    "#                 \"Il s‚Äôagit d‚Äôun corpus d‚Äôinterventions de d√©put√©s √† l‚Äôassembl√©e nationale en France lors de la 16e l√©gislature.\"\n",
    "#                 \" La ¬´ R√©publique ¬ª renvoie ici √† sa dimension id√©elle ou id√©ologique. Est donc exclut les r√©f√©rences √† des pays, au nom d‚Äôun parti politique, d‚Äôun journaliste ou d‚Äôune institution, ou √† la fonction de pr√©sident de la R√©publique. Est inclut en plus du champ lexical de la ¬´ R√©publique ¬ª, √† la devise ¬´ libert√©, √©galit√©, fraternit√© ¬ª et aux principes de ¬´ la√Øcit√© ¬ª, ¬´ universalisme ¬ª et ¬´ indivisibilit√© ¬ª. \"\n",
    "#                 \"Classifie chaque intervention comme 'REPUBLIQUE' ou 'AUTRE'\"\n",
    "#                 \"R√©ponds uniquement par un de ces deux mots.\"\n",
    "#             ),\n",
    "#         },\n",
    "#         {\"role\": \"user\", \"content\": f'Classe cette intervention :\\n\"{text}\"\\nLabel:'},\n",
    "#     ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e8ab6f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 100/100 [100%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Temps d'ex√©cution : 78.47 secondes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# import time\n",
    "\n",
    "# # test avec un extrait\n",
    "# texts = df[\"Texte\"][:100]  # ou .iloc[:10]\n",
    "\n",
    "# start = time.time()\n",
    "# # Appel\n",
    "# r_ollama = do_predictions(get_prompt_long, texts, model=\"llama3.1:70b\")\n",
    "# end = time.time()\n",
    "# print(f\"Temps d'ex√©cution : {end - start:.2f} secondes\")\n",
    "\n",
    "# # Ajout dans le DataFrame\n",
    "# df.loc[texts.index, \"prediction_long\"] = r_ollama"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a88af42e",
   "metadata": {},
   "source": [
    "# Experimentation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "108545e0",
   "metadata": {},
   "source": [
    "## Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "7d55c357",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"prediction_llama_simple\"] = df[\"prediction_llama_simple\"].replace(\n",
    "    {\"REPUBLIQUE\": \"Republique\", \"AUTRE\": \"Autre\"}\n",
    ")\n",
    "\n",
    "df[\"prediction_llama_exclure_pays\"] = df[\"prediction_llama_exclure_pays\"].replace(\n",
    "    {\"REPUBLIQUE\": \"Republique\", \"AUTRE\": \"Autre\"}\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "0fdd434e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>previous_annotation</th>\n",
       "      <th>prediction_llama_simple</th>\n",
       "      <th>prediction_llama_exclure_pays</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Republique</td>\n",
       "      <td>Republique</td>\n",
       "      <td>Republique</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Autre</td>\n",
       "      <td>Republique</td>\n",
       "      <td>Autre</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Republique</td>\n",
       "      <td>Autre</td>\n",
       "      <td>Republique</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Republique</td>\n",
       "      <td>Autre</td>\n",
       "      <td>Republique</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Republique</td>\n",
       "      <td>Republique</td>\n",
       "      <td>Republique</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Republique</td>\n",
       "      <td>Republique</td>\n",
       "      <td>Republique</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Republique</td>\n",
       "      <td>Republique</td>\n",
       "      <td>Republique</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Republique</td>\n",
       "      <td>Autre</td>\n",
       "      <td>Republique</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Autre</td>\n",
       "      <td>Autre</td>\n",
       "      <td>Republique</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Republique</td>\n",
       "      <td>Republique</td>\n",
       "      <td>Republique</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows √ó 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   previous_annotation prediction_llama_simple prediction_llama_exclure_pays\n",
       "0           Republique              Republique                    Republique\n",
       "1                Autre              Republique                         Autre\n",
       "2           Republique                   Autre                    Republique\n",
       "3           Republique                   Autre                    Republique\n",
       "4           Republique              Republique                    Republique\n",
       "..                 ...                     ...                           ...\n",
       "95          Republique              Republique                    Republique\n",
       "96          Republique              Republique                    Republique\n",
       "97          Republique                   Autre                    Republique\n",
       "98               Autre                   Autre                    Republique\n",
       "99          Republique              Republique                    Republique\n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[[\"previous_annotation\", \"prediction_llama_simple\", \"prediction_llama_exclure_pays\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "85769158",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>previous_annotation</th>\n",
       "      <th>prediction_llama_simple</th>\n",
       "      <th>prediction_llama_exclure_pays</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3088159</td>\n",
       "      <td>Les Jeux olympiques et paralympiques sont une ...</td>\n",
       "      <td>Republique</td>\n",
       "      <td>Republique</td>\n",
       "      <td>Republique</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2930452</td>\n",
       "      <td>C‚Äôest pourquoi notre texte demande l‚Äôexclusion...</td>\n",
       "      <td>Autre</td>\n",
       "      <td>Republique</td>\n",
       "      <td>Autre</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3325331</td>\n",
       "      <td>Peut-√™tre, mais quoi qu‚Äôil en soit, le pr√©side...</td>\n",
       "      <td>Republique</td>\n",
       "      <td>Autre</td>\n",
       "      <td>Republique</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3488029</td>\n",
       "      <td>Ainsi que nous l‚Äôavons d√©j√† exprim√© en commiss...</td>\n",
       "      <td>Republique</td>\n",
       "      <td>Autre</td>\n",
       "      <td>Republique</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3487031</td>\n",
       "      <td>La s√©curit√© sociale ¬´ est la garantie donn√©e √†...</td>\n",
       "      <td>Republique</td>\n",
       "      <td>Republique</td>\n",
       "      <td>Republique</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id                                               text  \\\n",
       "0  3088159  Les Jeux olympiques et paralympiques sont une ...   \n",
       "1  2930452  C‚Äôest pourquoi notre texte demande l‚Äôexclusion...   \n",
       "2  3325331  Peut-√™tre, mais quoi qu‚Äôil en soit, le pr√©side...   \n",
       "3  3488029  Ainsi que nous l‚Äôavons d√©j√† exprim√© en commiss...   \n",
       "4  3487031  La s√©curit√© sociale ¬´ est la garantie donn√©e √†...   \n",
       "\n",
       "  previous_annotation prediction_llama_simple prediction_llama_exclure_pays  \n",
       "0          Republique              Republique                    Republique  \n",
       "1               Autre              Republique                         Autre  \n",
       "2          Republique                   Autre                    Republique  \n",
       "3          Republique                   Autre                    Republique  \n",
       "4          Republique              Republique                    Republique  "
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import classification_report, f1_score\n",
    "\n",
    "# df_score = pd.read_csv(\"../data/interim/df_merged_pred.csv\")\n",
    "df_score = df[[\"id\", \"text\", \"previous_annotation\", \"prediction_llama_simple\", \"prediction_llama_exclure_pays\"]]\n",
    "df_score.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "a8339845",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Autre      0.667     0.250     0.364         8\n",
      "  Republique      0.938     0.989     0.963        92\n",
      "\n",
      "    accuracy                          0.930       100\n",
      "   macro avg      0.802     0.620     0.663       100\n",
      "weighted avg      0.916     0.930     0.915       100\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# pour le principe, puisque ici pas de gold standard, juste les mod√®les entre eux\n",
    "print(\n",
    "    classification_report(\n",
    "        df_score[\"previous_annotation\"], df_score[\"prediction_llama_exclure_pays\"], digits=3\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "cacea899",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6632996632996633"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(\n",
    "    df_score[\"previous_annotation\"],\n",
    "    df_score[\"prediction_llama_exclure_pays\"],\n",
    "    average=\"macro\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "7e555ff8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>prediction_llama_exclure_pays</th>\n",
       "      <th>Autre</th>\n",
       "      <th>Republique</th>\n",
       "      <th>Total</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>previous_annotation</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Autre</th>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Republique</th>\n",
       "      <td>1</td>\n",
       "      <td>91</td>\n",
       "      <td>92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Total</th>\n",
       "      <td>3</td>\n",
       "      <td>97</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "prediction_llama_exclure_pays  Autre  Republique  Total\n",
       "previous_annotation                                    \n",
       "Autre                              2           6      8\n",
       "Republique                         1          91     92\n",
       "Total                              3          97    100"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# comparer les mod√®les\n",
    "pd.crosstab(\n",
    "    df_score[\"previous_annotation\"],\n",
    "    df_score[\"prediction_llama_exclure_pays\"],\n",
    "    margins=True,\n",
    "    margins_name=\"Total\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67121355",
   "metadata": {},
   "source": [
    "## Few-shot ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54426f76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Let's build the prompt, with some examples\n",
    "# few_shot_examples = [\n",
    "#         (\"Biden signs executive order on student debt relief\", \"POLITICS\"),\n",
    "#         (\"Amazon launches new AI-powered Alexa features\", \"OTHER\"),\n",
    "#         (\"Congress debates military spending bill\", \"POLITICS\"),\n",
    "#         (\"PSG wins much-anticipated Champions League\", \"OTHER\")\n",
    "#         ]\n",
    "\n",
    "# def get_prompt_few_shots(text: str, examples: list[tuple] = few_shot_examples):\n",
    "#   examples = \"\\n\".join([f\"Classify this headline:\\n{headline}\\nLabel: {label}\\n\\n\" for headline, label in examples])\n",
    "#   return [{\"role\":\"system\",\n",
    "#            \"content\":\"You are a strict news classifier. You must respond with one word only ‚Äî either 'POLITICS' or 'OTHER'.\" +\n",
    "#            \"\\n Do not explain. Do not output anything else.\"\n",
    "\n",
    "#            },\n",
    "#            {\"role\":\"user\",\"content\": f\"{examples}\\nClassify this headline:\\n\\\"{text}\\\"\\nLabel:\"}\n",
    "#   ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d771928",
   "metadata": {},
   "source": [
    "## Refacto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b0b9332",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Inspiration GPT pour avoir des checkpoints :\n",
    "# results = []\n",
    "# indexes = []\n",
    "# batch_size = 20\n",
    "\n",
    "# for i in range(0, len(df), batch_size):\n",
    "#     batch = df[\"Texte\"].iloc[i:i+batch_size]\n",
    "#     try:\n",
    "#         r_batch, _ = do_predictions(get_prompt, batch, model=\"llama3.1:70b\")\n",
    "#         results.extend(r_batch)\n",
    "#         indexes.extend(batch.index)\n",
    "\n",
    "#         # Checkpoint every 100 samples\n",
    "#         if i % 100 == 0:\n",
    "#             df.loc[indexes, \"prediction_simple\"] = results\n",
    "#             df.to_csv(\"checkpoint_predictions.csv\", index=False)\n",
    "#             print(f\"Checkpoint sauvegard√© √† {i}.\")\n",
    "\n",
    "#         time.sleep(1)  # optional pause\n",
    "\n",
    "#     except Exception as e:\n",
    "#         print(f\"Erreur au batch {i}: {e}\")\n",
    "#         continue\n",
    "\n",
    "# df.loc[indexes, \"prediction_simple\"] = results\n",
    "# df.to_csv(\"final_predictions.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdf68914",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Et m√™me inspiration pour un truc encore plus complet, mais overkill pour l'instant\n",
    "\n",
    "# import os\n",
    "# import time\n",
    "# import pandas as pd\n",
    "# from datetime import datetime\n",
    "\n",
    "\n",
    "# def ensure_dir(path):\n",
    "#     if not os.path.exists(path):\n",
    "#         os.makedirs(path)\n",
    "\n",
    "\n",
    "# def timestamp():\n",
    "#     return datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "\n",
    "\n",
    "# def do_predictions(prompt_func, texts, model):\n",
    "#     prompt_name = prompt_func.__name__\n",
    "#     results = [prompt_func(text) for text in texts]\n",
    "#     return results, prompt_name\n",
    "\n",
    "\n",
    "# def run_llm_batches(df, text_column, prompt_func, model,\n",
    "#                     column_name=None, batch_size=20, sleep_time=1,\n",
    "#                     checkpoint_every=100, output_dir=\"outputs\"):\n",
    "\n",
    "#     # Setup\n",
    "#     start = time.time()\n",
    "#     all_results = []\n",
    "#     all_indexes = []\n",
    "#     name = prompt_func.__name__ if column_name is None else column_name\n",
    "\n",
    "#     ensure_dir(output_dir)\n",
    "\n",
    "#     print(f\"üöÄ D√©but du traitement avec le prompt '{name}' et le mod√®le '{model}'\")\n",
    "\n",
    "#     # Boucle par batch\n",
    "#     for i in range(0, len(df), batch_size):\n",
    "#         batch = df[text_column].iloc[i:i + batch_size]\n",
    "#         idx = batch.index\n",
    "\n",
    "#         try:\n",
    "#             batch_start = time.time()\n",
    "#             r_batch, _ = do_predictions(prompt_func, batch, model=model)\n",
    "#             all_results.extend(r_batch)\n",
    "#             all_indexes.extend(idx)\n",
    "#             print(f\"‚úÖ Batch {i}-{i + batch_size} trait√© en {time.time() - batch_start:.2f}s\")\n",
    "\n",
    "#             # Sauvegarde p√©riodique\n",
    "#             if (i // batch_size) % (checkpoint_every // batch_size) == 0:\n",
    "#                 df.loc[all_indexes, name] = all_results\n",
    "#                 ckpt_file = os.path.join(output_dir, f\"checkpoint_{name}_{timestamp()}.csv\")\n",
    "#                 df.to_csv(ckpt_file, index=False)\n",
    "#                 print(f\"üíæ Checkpoint enregistr√© : {ckpt_file}\")\n",
    "\n",
    "#             time.sleep(sleep_time)\n",
    "\n",
    "#         except Exception as e:\n",
    "#             print(f\"‚ö†Ô∏è Erreur au batch {i}-{i + batch_size}: {e}\")\n",
    "#             continue\n",
    "\n",
    "#     # R√©sultat final\n",
    "#     df.loc[all_indexes, name] = all_results\n",
    "#     final_file = os.path.join(output_dir, f\"final_{name}_{timestamp()}.csv\")\n",
    "#     df.to_csv(final_file, index=False)\n",
    "\n",
    "#     print(f\"üèÅ Traitement termin√© en {time.time() - start:.2f}s\")\n",
    "#     print(f\"üìù R√©sultat final enregistr√© : {final_file}\")\n",
    "#     return df\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
