{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "15f284a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# bug incompatibilité dans myenv_clone, ok dans nlp_env\n",
    "# faire du nettoyage dans les envs un jour …\n",
    "import os\n",
    "from ollama import Client\n",
    "\n",
    "OLLAMA_HOST = os.environ.get(\"OLLAMA_HOST\")\n",
    "client = Client(host=OLLAMA_HOST)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b5bf4d1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"../data/df_match.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0bf29366",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model='llama3.2' created_at='2025-06-26T14:35:44.364221377Z' done=True done_reason='stop' total_duration=1291411302 load_duration=14430832 prompt_eval_count=31 prompt_eval_duration=1834207 eval_count=283 eval_duration=1274251929 message=Message(role='assistant', content=\"The sky appears blue because of a phenomenon called Rayleigh scattering, named after the British physicist Lord Rayleigh, who first described it in the late 19th century.\\n\\nHere's what happens:\\n\\n1. Sunlight enters Earth's atmosphere and is made up of different wavelengths (colors) of light.\\n2. The shorter (blue) wavelengths are scattered more than the longer (red) wavelengths by the tiny molecules of gases such as nitrogen and oxygen in the atmosphere.\\n3. This scattering effect is more pronounced for blue light because it has a smaller wavelength, which means it's more easily deflected by the tiny molecules.\\n4. As a result, when sunlight enters our eyes, we see mostly the scattered blue light, making the sky appear blue.\\n\\nIt's worth noting that the color of the sky can vary depending on the time of day, atmospheric conditions, and other factors. For example:\\n\\n* During sunrise and sunset, the sky often takes on hues of red, orange, and pink due to the scattering of longer wavelengths.\\n* In areas with high levels of pollution or dust, the sky may appear more gray or hazy.\\n* At night, the sky can appear darker because our eyes are adapted to see in low light conditions.\\n\\nHowever, under clear conditions, the blue color of the sky is a result of Rayleigh scattering and remains one of the most iconic and striking features of our natural world.\", images=None, tool_calls=None)\n"
     ]
    }
   ],
   "source": [
    "# # test\n",
    "# response = client.chat(\n",
    "#     model=\"llama3.2\",\n",
    "#     messages=[\n",
    "#         {\n",
    "#             \"role\": \"user\",\n",
    "#             \"content\": \"Why is the sky blue?\",\n",
    "#         },\n",
    "#     ],\n",
    "# )\n",
    "# print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e888d025",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prompt(text):\n",
    "    return [\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": (\n",
    "                \"Tu es un expert politique. \"\n",
    "                \"Classifie chaque intervention comme 'REPUBLIQUE' ou 'AUTRE'. \"\n",
    "                \"Réponds uniquement par un de ces deux mots.\"\n",
    "            ),\n",
    "        },\n",
    "        {\"role\": \"user\", \"content\": f'Classe cette intervention :\\n\"{text}\"\\nLabel:'},\n",
    "    ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ed61b36",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "def do_predictions(prompt_generator, texts, model):\n",
    "    \"\"\"\n",
    "    Inference avec Ollama : prompt_generator, liste de textes, modèle.\n",
    "    Affiche la progression avec tqdm (en %).\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    total = len(texts)\n",
    "\n",
    "    with tqdm(\n",
    "        total=total,\n",
    "        desc=\"Progress\",\n",
    "        unit=\"item\",\n",
    "        bar_format=\"{l_bar}{bar} | {n_fmt}/{total_fmt} [{percentage:3.0f}%]\",\n",
    "    ) as pbar:\n",
    "        for i, text in texts.items():\n",
    "            try:\n",
    "                messages = prompt_generator(text)\n",
    "                response = client.chat(model=model, messages=messages)\n",
    "                content = response.get(\"message\", {}).get(\"content\", \"\").strip()\n",
    "                results.append(content)\n",
    "            except Exception as e:\n",
    "                print(f\"Erreur ligne {i} : {e}\")\n",
    "                results.append(None)\n",
    "            pbar.update(1)\n",
    "\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0a5a949b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress: 100%|██████████ | 100/100 [100%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Temps d'exécution : 70.52 secondes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "# test avec un extrait\n",
    "texts = df[\"Texte\"][:100]  # ou .iloc[:10]\n",
    "\n",
    "start = time.time()\n",
    "# Appel\n",
    "r_ollama = do_predictions(get_prompt, texts, model=\"llama3.1:70b\")\n",
    "end = time.time()\n",
    "print(f\"Temps d'exécution : {end - start:.2f} secondes\")\n",
    "\n",
    "# Ajout dans le DataFrame\n",
    "df.loc[texts.index, \"prediction\"] = r_ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e8341764",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pred = df[[\"ID_paragraphe\", \"prediction\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a644215b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pred.to_csv(\"../data/intermediate/df_pred\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
